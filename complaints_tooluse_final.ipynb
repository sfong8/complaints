{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7c1cd-c9a1-4ee3-813a-c7433d64efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json, math\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "import boto3\n",
    "import pandas as pd\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name='us-east-1',\n",
    ")\n",
    "embeddings = BedrockEmbeddings(\n",
    "            client=bedrock_client, \n",
    "            model_id=\"amazon.titan-embed-text-v2:0\"\n",
    "        )\n",
    "vector_store = FAISS.load_local('complaints.vs',embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d7c74b-d26b-477b-b38e-370d7509de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/complaints/rag_functions.py:15: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockEmbeddings`.\n",
      "  embeddings = BedrockEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from rag_functions import getContext,getResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10e71ce-c478-4969-8c19-cab1087bd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_query = 'Summarise the complaints by the client region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edbb4e5b-a3b5-4164-81b7-3caf03405db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '9424ff23-f42e-40da-8a96-ae399fbcb64c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 18 Jan 2025 21:12:11 GMT', 'content-type': 'application/json', 'content-length': '600', 'connection': 'keep-alive', 'x-amzn-requestid': '9424ff23-f42e-40da-8a96-ae399fbcb64c'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '<thinking> The user wants to summarize complaints by the client region. This means I need to filter complaints based on the client region. Since the user did not specify a particular region or number of documents, I will use the default settings. </thinking>\\n'}, {'toolUse': {'toolUseId': 'tooluse_nHCh0WqNTIOU8GSXoriF_Q', 'name': 'identify_complaints_filters', 'input': {'x': {'client_region': ['MC', 'LC', 'ICB']}, 'y': 100}}}]}}, 'stopReason': 'tool_use', 'usage': {'inputTokens': 841, 'outputTokens': 168, 'totalTokens': 1009}, 'metrics': {'latencyMs': 1373}}\n",
      "filter by metadata: {'client_region': ['MC', 'LC', 'ICB']} and k: 100\n"
     ]
    }
   ],
   "source": [
    "contxt_df = getContext(query_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101795e5-da84-4f7b-990d-ad485252fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = getResponse(query_query,contxt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9eeb88c-1a68-4b1c-acc7-16571ba21876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a summary of the complaints by client region:\\n\\n### ICB (International Corporate Banking)\\n- **Payments**:\\n  - Xi Solutions Group: A scheduled payment was not executed, causing a breach of contract with a client.\\n  - Xi Prime Solutions: A scheduled payment was not executed, causing a breach of contract with a client.\\n  - Lambda Trade Solutions: A payment to a foreign supplier was not completed on time, resulting in a fine.\\n  - Lambda Prime Trade: A payment to a foreign supplier was not completed on time, resulting in a fine.\\n  - Beta Prime Ltd: An international payment was not completed on time, resulting in a penalty from the recipient.\\n  - Rho Global Corp: An international payment was incorrectly converted, resulting in a financial loss.\\n\\n### MC (Mainstream Corporate)\\n- **Customer Service**:\\n  - Omega Holdings Ltd: Unable to reach a representative for over a week regarding an account issue.\\n  - Tech Innovators Corp: The customer service team was unresponsive to queries regarding account discrepancies.\\n  - Mu Holdings Ltd: Waiting over a week for a response to a service request.\\n  - Mu Prime Holdings: Waiting over a week for a response to a service request.\\n  - Sigma Solutions Inc: Have not received a callback from the support team despite multiple attempts.\\n  - Sigma Prime Solutions: Have not received a callback from the support team despite multiple attempts.\\n- **Account Management**:\\n  - Gamma Prime Corp: Account was incorrectly linked to another client's account, causing confusion.\\n\\n### LC (Local Corporate)\\n- **Digital Channel**:\\n  - Pi Financial Services: Website experiencing frequent timeouts, disrupting financial operations.\\n  - Pi Prime Financial: Website experiencing frequent timeouts, disrupting financial operations.\\n  - Eta Enterprises Ltd: Mobile app not syncing with the online portal, leading to data inconsistencies.\\n  - Eta Prime Inc: Mobile app not syncing with the online portal, leading to data inconsistencies.\\n  - Delta Prime Solutions: Website not responsive, making it impossible to conduct transactions.\\n  - Tau Enterprises Ltd: Mobile app not compatible with new devices, causing access issues.\\n  - Delta Financial Services: Website not loading properly, making it impossible to conduct transactions.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf63f56-5369-4775-b315-d43707048bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_bedrock(message_list,system_prompts, tool_list,extract_filter=True):\n",
    "    session = boto3.Session()\n",
    "\n",
    "    bedrock = session.client(service_name='bedrock-runtime')\n",
    "    if extract_filter:\n",
    "        response = bedrock.converse(\n",
    "            modelId=\"amazon.nova-pro-v1:0\",\n",
    "            messages=message_list,\n",
    "            system= [{ 'text':system_prompts  }],\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": 2000,\n",
    "                \"temperature\": 0.2\n",
    "            },\n",
    "            toolConfig={ \"tools\": tool_list }\n",
    "        )\n",
    "    else:\n",
    "            response = bedrock.converse(\n",
    "            modelId=\"amazon.nova-pro-v1:0\",\n",
    "            messages=message_list,\n",
    "            system= [{ 'text':system_prompts  }],\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": 2000,\n",
    "                \"temperature\": 0.2\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e39c66-b10d-4652-b805-74c2d70cfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool_list =[\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"identify_complaints_filters\",\n",
    "            \"description\": \"\"\"Your job is to first look at the query's query and determine if it requires filtering the complaints first based off the following columns \n",
    "            client_name - name of the company making the complaint, you will need to use the like filter since users might not type if the exact name\n",
    "            client_region - possible values ['MC','LC','ICB'] where MC= mid-corporate, LC = Large corporate, ICB = International corprorate\n",
    "            complaint_date - date of the complaint\n",
    "\n",
    "            Note: if you're not sure then don't output anything. This is used for metadata filter for the vectorstore. There are two outputs x and y, where x is the column filters and y is the number of documents to return - if user doesnt specify then default is 100\n",
    "\n",
    "            Example1: user_query: Show me all complaints in region MC\n",
    "            output: = {'metadata_filter': {client_region\": \"MC\"},'k_filter':100}\n",
    "\n",
    "            Example2: user_query: Show me all complaints in region LC and after 15th June 2024\n",
    "            output: {'metadata_filter':{\"client_region\": \"MC\",\"complaint_date\": \">2024-06-15\"},'k_filter':100}\n",
    "\n",
    "\n",
    "            Example3: user_query: Show me 5 complaints in regions MC and LC\n",
    "            output: {'metadata_filter':{client_region\": [\"MC\",'LC']},'k_filter':5}          \n",
    "            \"\"\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"x\": {\n",
    "                            \"type\": \"dict\",\n",
    "                            \"description\": \"\"\"output filter as a dict e.g. {client_region\": [\"MC\",'LC']}  or {client_region\": \"MC\"}\"\"\"\n",
    "                        },\n",
    "                        \"y\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"\"\"Filter for the number of documents to return. if user query doesnt specify then default is 100\"\"\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"x\",\"y\"]\n",
    "                }\n",
    "            }\n",
    "        }}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1865c-d42a-41f4-87f6-a9468942ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContext(user_prompt:str,vector_store,tool_list):\n",
    "    system_message_filter = \"\"\"You are an AI assistant within a corporate bank in the Complaints team. Your role is to retrieve back the complaints based off the user query. \n",
    "    Your first job is always to breakdown the user query (using the tool identify_complaints_filters) \"\"\"\n",
    "    message_list = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [ { \"text\": user_prompt } ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    filter_response = call_bedrock(message_list=message_list,system_prompts=system_message_filter,tool_list=tool_list,extract_filter=True)\n",
    "    print(filter_response)\n",
    "    try:\n",
    "        metadata_filter = filter_response['output']['message']['content'][1]['toolUse']['input']['x']\n",
    "        k_filter = filter_response['output']['message']['content'][1]['toolUse']['input']['y']\n",
    "        print(f\"filter by metadata: {metadata_filter} and k: {k_filter}\")\n",
    "        retriever = vector_store.as_retriever(search_kwargs={'filter': metadata_filter, 'k':k_filter})\n",
    "    except:\n",
    "        print('cannot extract out filters so going default')\n",
    "        retriever = vector_store.as_retriever(search_kwargs= {'k':100})\n",
    "\n",
    "    docs = retriever.invoke(user_prompt)\n",
    "    \n",
    "    master_df = pd.DataFrame()\n",
    "    for doc in docs:\n",
    "        test=doc.metadata\n",
    "        test.update({'complaint_text':doc.page_content})\n",
    "        temp_df = pd.DataFrame([test.values()],columns=test.keys())\n",
    "        master_df = pd.concat([master_df,temp_df])\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae98f8-d4e4-4705-b2a9-e59535ad0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(user_prompt:str,vector_store,tool_list):\n",
    "    message_list = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [ { \"text\": user_prompt } ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    context_df = getContext(user_prompt,vector_store,tool_list)\n",
    "\n",
    "    \n",
    "    rag_system_message = f\"\"\"\n",
    "    System: You are an AI assistant in a corporate bank and your job is to answer the users query around complaints using only the context only you should mainly use the complaint_text column to generate answer but can use other columns to check the user query. \n",
    "    Human: Here is a set of context, contained in <context> tags:\n",
    "    \n",
    "    <context>\n",
    "    {context_df.to_csv(index=False)}\n",
    "    </context>\n",
    "    \n",
    "     If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = call_bedrock(message_list=message_list,system_prompts=rag_system_message,tool_list=None,extract_filter=False)\n",
    "    return response['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42817e85-9cdf-4786-a8ca-e4590a67ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0716bb3-147e-4a58-a10d-df4012ce21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_query='is there any complaints relating to supply chain for clients in MC region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1418119-a261-4fdb-b432-9dc3672e66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_query = 'Summarise the complaints by the client region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e4eb0-ce46-4e38-84c3-9c580a197d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ed3a0-6c56-436c-8cac-9c341afdba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = getResponse(user_prompt=query_query,vector_store=vector_store,tool_list=tool_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccecb19-6db2-4b34-97ec-0e68925fe831",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bdda6-108d-4152-a485-70f16d9da2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2922d-861b-483a-814a-b1faff34240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolError(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc204d62-c6f4-4ba8-9b12-cb906b96c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_result(tool_use_block):\n",
    "\n",
    "    tool_use_name = tool_use_block['name']\n",
    "            \n",
    "    print(f\"Using tool {tool_use_name}\")\n",
    "    \n",
    "    # Note: We're deliberately excluding tangent so something magical can happen\n",
    "    try:\n",
    "        return [tool_use_block['input']['x'], tool_use_block['input']['y']]\n",
    "    except:\n",
    "        raise ToolError(f\"Tooluse input does not contain valid filter terms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df975337-867a-480d-af61-cf4d492495e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_response(response_message):\n",
    "    \n",
    "    response_content_blocks = response_message['content']\n",
    "    \n",
    "    follow_up_content_blocks = []\n",
    "    \n",
    "    for content_block in response_content_blocks:\n",
    "        if 'toolUse' in content_block:\n",
    "            tool_use_block = content_block['toolUse']\n",
    "            \n",
    "            try:\n",
    "                tool_result_value = get_tool_result(tool_use_block)\n",
    "                \n",
    "                if tool_result_value is not None:\n",
    "                    follow_up_content_blocks.append({\n",
    "                        \"toolResult\": {\n",
    "                            \"toolUseId\": tool_use_block['toolUseId'],\n",
    "                            \"content\": [\n",
    "                                { \"json\": { \"result\": tool_result_value } }\n",
    "                            ]\n",
    "                        }\n",
    "                    })\n",
    "                \n",
    "            except ToolError as e:\n",
    "                follow_up_content_blocks.append({ \n",
    "                    \"toolResult\": {\n",
    "                        \"toolUseId\": tool_use_block['toolUseId'],\n",
    "                        \"content\": [  { \"text\": repr(e) } ],\n",
    "                        \"status\": \"error\"\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "    \n",
    "    if len(follow_up_content_blocks) > 0:\n",
    "        \n",
    "        follow_up_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": follow_up_content_blocks,\n",
    "        }\n",
    "        \n",
    "        return follow_up_message\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36120b69-3fd2-4c50-97f9-5f01e9760723",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_loop(query_query,tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d775fe0-b363-4b93-921f-2eedbee0da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58c144-1e31-458a-afa4-394ffb96b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_system_message = f\"\"\"\n",
    "System: You are an AI assistant in a corporate bank and your job is to answer the users query around complaints using only the context only you should mainly use the complaint_text column to generate answer but can use other columns to check the user query. \n",
    "Human: Here is a set of context, contained in <context> tags:\n",
    "\n",
    "<context>\n",
    "{master_df.to_csv(index=False)}\n",
    "</context>\n",
    "\n",
    " If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce9476-b145-435a-a971-e8a8b75cb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_system_message = f\"\"\"\n",
    "System: You are an AI assistant in a corporate bank and your job is to answer the users query around complaints using only the context only you should mainly use the complaint_text column to generate answer but can use other columns to check the user query. \n",
    "Human: Here is a set of context, contained in <context> tags:\n",
    "\n",
    "<context>\n",
    "{master_df.to_csv(index=False)}\n",
    "</context>\n",
    "\n",
    " If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175d991-e47a-4713-bd66-92821efbef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loop(prompt, tool_list):\n",
    "    MAX_LOOPS = 6\n",
    "    loop_count = 0\n",
    "    continue_loop = True\n",
    "    system_message_filter = \"\"\"You are an AI assistant within a corporate bank in the Complaints team. Your role is to retrieve back the complaints based off the user query. \n",
    "Your first job is always to breakdown the user query (using the tool identify_complaints_filters) to determine if you need to filter the metadata in the vectorstore first\"\"\"\n",
    "\n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [ { \"text\": prompt } ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    while continue_loop:\n",
    "        response = call_bedrock(message_list=message_list,system_prompts=system_message_filter,tool_list=tool_list)\n",
    "        \n",
    "        response_message = response['output']['message']\n",
    "        message_list.append(response_message)\n",
    "        \n",
    "        loop_count = loop_count + 1\n",
    "        \n",
    "        if loop_count >= MAX_LOOPS:\n",
    "            print(f\"Hit loop limit: {loop_count}\")\n",
    "            break\n",
    "        \n",
    "        follow_up_message = handle_response(response_message)\n",
    "        \n",
    "        if follow_up_message is None:\n",
    "            # No remaining work to do, return final response to user\n",
    "            continue_loop = False \n",
    "        else:\n",
    "            message_list.append(follow_up_message)\n",
    "            \n",
    "    return message_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b9298-f09b-49bb-bb8f-ae57adbf6a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
